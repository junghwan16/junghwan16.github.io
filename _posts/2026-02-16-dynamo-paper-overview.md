---
layout: single
title: "Amazon Dynamo 논문 정리"
date: 2026-02-16 17:00:00 +0900
categories: [backend, infrastructure]
---

2007년 Amazon이 발표한 Dynamo 논문은 분산 시스템 역사에서 하나의 전환점이다. 이 논문 이후 Cassandra, Riak, Voldemort 등 수많은 NoSQL 시스템이 등장했고, "최종 일관성으로도 프로덕션을 돌릴 수 있다"는 것을 실증한 첫 번째 사례가 되었다.

이 글에서는 Dynamo 논문의 핵심 내용을 정리한다.

**참고:** 논문에 나오는 Dynamo와 AWS의 DynamoDB는 같은 철학에서 출발했지만, 다른 시스템이다.

---

## 먼저 생각해볼 것 — 왜 key-value인가

Amazon 플랫폼에는 데이터 저장소에 접근하는 데 기본 키(primary key)만 사용하는 것으로 충분한 서비스들이 많다. 베스트 셀러 목록, 장바구니, 세션 관리, 판매 순위, 상품 카탈로그 등이 그렇다.

이런 서비스에 RDBMS를 사용하면 어떻게 될까?

- 복잡한 쿼리, 관리 기능 등 필요하지 않은 기능들이 비싼 하드웨어와 높은 숙련도를 요구한다.
- 복제 기술이 제한된다.
- 스케일 아웃이 어렵다.

Dynamo는 이런 서비스들을 위해 **단순한 key-value 인터페이스**를 제공한다. `get(key)`와 `put(key, context, object)`, 이 두 가지가 전부다.

---

## 시스템 요구 사항

Dynamo는 다음과 같은 요구 사항을 전제로 설계되었다.

**쿼리 모델**

기본 키로만 읽고 쓴다. 여러 키에 걸친 연산은 없다.

**ACID 트레이드오프**

ACID를 보장하는 저장소는 [가용성](/backend/infrastructure/availability/)이 떨어지는 경향이 있다. Dynamo는 높은 가용성을 얻기 위해 약한 [일관성](/backend/infrastructure/consistency/)(ACID에서 "C")을 허용한다. 고립성(Isolation)을 보장하지 않으며, 단일 키 업데이트만 허용한다.

고립성을 보장하지 않지만 단일 키 업데이트만 허용하므로, 여러 키에 걸친 트랜잭션 자체가 없어서 문제가 단순해진다.

**효율**

[99.9분위에서 측정하는 엄격한 레이턴시 요구 사항](/backend/infrastructure/sla/)을 따른다. 평균이 아니라 꼬리 지연(tail latency)을 기준으로 삼는다는 점이 중요하다.

---

## 설계 철학

네트워크 장애의 가능성 때문에 강력한 일관성과 높은 가용성을 동시에 달성할 수 없다(CAP 정리). Dynamo는 이 트레이드오프에서 **가용성**을 선택했다.

### Always Writeable

Dynamo의 가장 핵심적인 설계 원칙이다.

전통적인 시스템은 쓰기 시점에 하나의 정답 상태를 강제한다. 리더 기반, 동기식 quorum, 합의 알고리즘 등을 써서 쓰기 때 이미 충돌을 없앤다. 읽기가 단순해지는 대신, 장애 시 쓰기가 실패할 수 있다.

Dynamo는 반대로 간다. **쓰기는 언제나 성공시키고, 충돌은 읽기 시점에 해결한다.** 서로 다른 파티션에서 서로 다른 값이 써질 수 있고, 복구 후에 충돌이 발생할 수 있다.

### 충돌 해결: 누가?

- **데이터 저장소가 해결**: "최종 쓰기 승리" 같은 단순한 정책
- **애플리케이션이 해결**: 비즈니스 로직을 반영한 병합 (예: 장바구니 union)

### 설계 원칙

| 원칙          | 설명                            |
| ------------- | ------------------------------- |
| 점진적 확장성 | 한 번에 하나의 노드를 추가/제거 |
| 대칭성        | 모든 노드가 동등한 책임         |
| 탈중앙성      | 피어 대 피어, 마스터 노드 없음  |
| 이질성        | 서버 용량에 비례한 작업 분배    |

---

## 핵심 기법 요약

Dynamo가 사용하는 기법들을 한눈에 정리하면 다음과 같다.

| 문제               | 기법                                                     | 장점                                             |
| ------------------ | -------------------------------------------------------- | ------------------------------------------------ |
| 파티셔닝           | [안정 해싱](/backend/infrastructure/consistent-hashing/) | 점진적 확장 가능                                 |
| 쓰기 고가용성      | 읽기 중 조정 가능한 벡터 클럭                            | 버전 크기와 업데이트 양의 분리                   |
| 일시적인 장애      | 느슨한 정족수와 임시 위탁(Hinted Handoff)                | 일부 레플리카 불능 시에도 고가용성과 내구성 보장 |
| 영구적인 장애      | 머클 트리를 통한 안티 엔트로피                           | 백그라운드에서 레플리카 동기화                   |
| 멤버십과 장애 감지 | 가십 기반 프로토콜                                       | 대칭성 유지, 중앙 레지스트리 불필요              |

각 기법의 상세 내용은 [벡터 클럭과 버전 충돌 해결](/backend/infrastructure/vector-clock-conflict-resolution/), [Dynamo의 장애 처리](/backend/infrastructure/dynamo-fault-tolerance/) 편에서 다룬다.

---

## 시스템 아키텍처

### 인터페이스

- `get(key)` — 키와 연결된 객체(또는 충돌 시 객체 목록)를 컨텍스트와 함께 반환
- `put(key, context, object)` — 레플리카 위치를 결정하고 디스크에 저장. 컨텍스트는 벡터 클럭 등의 시스템 메타데이터

키에 MD5 해시를 적용해 128비트 식별자를 생성하고, 이를 기반으로 담당 저장소 노드를 결정한다.

### 파티셔닝

[안정 해싱(Consistent Hashing)](/backend/infrastructure/consistent-hashing/)에 의존하여 여러 저장소 호스트들에게 부하를 분산한다. 각 노드는 링 위의 여러 위치(Virtual Node)를 차지하여 부하 균형을 맞춘다.

### 복제

데이터를 N개 노드에 저장한다.

```
N=3일 때, 키가 B에 매핑되면:

  A ─── B ─── C ─── D ─── E
        ↓     ↓     ↓
      원본  복제1  복제2

B, C, D에 저장 (시계 방향)
```

이 노드 목록을 **선호 목록(Preference List)**이라 한다.

### N, R, W 파라미터

- **N** — 데이터를 저장할 노드 수 (복제본 수)
- **R** — 읽기 성공에 필요한 최소 응답 노드 수
- **W** — 쓰기 성공에 필요한 최소 응답 노드 수

`put(k, v)` 흐름:

1. 코디네이터 노드가 클라이언트 요청을 받는다
2. 선호 목록의 N개 노드에 write 요청을 전송한다
3. W개 응답이 오면 클라이언트에게 성공을 반환한다 (나머지는 비동기 전파)

---

## 관련 연구 포지셔닝

### P2P 시스템과의 비교

| 세대  | 시스템            | 특징                  | Dynamo와의 차이                                              |
| ----- | ----------------- | --------------------- | ------------------------------------------------------------ |
| 1세대 | Freenet, Gnutella | 비구조화, 확장성 한계 | 구조화된 DHT 사용                                            |
| 2세대 | Pastry, Chord     | O(log N) 홉 라우팅    | **제로 홉 DHT** — 모든 노드가 전체 라우팅 정보를 로컬에 보유 |

제로 홉 DHT가 가능한 이유는 노드 수가 수백 대 규모이기 때문이다. 퍼블릭 P2P(수만~수백만 노드)에서는 불가능한 전략이다.

### 분산 파일 시스템/DB와의 비교

| 시스템   | 특징                             | Dynamo와의 차이                |
| -------- | -------------------------------- | ------------------------------ |
| GFS      | 중앙집중식 마스터                | 탈중앙                         |
| Bigtable | 단일 마스터, 풍부한 데이터 모델  | 가용성보다 일관성에 무게       |
| Bayou    | 최종 일관성, 앱에 충돌 해결 위임 | 최종 순서를 확정하는 점이 다름 |

Dynamo의 차별화 포인트는 세 가지다.

1. **항상 쓰기 가능** — 장애나 동시 쓰기에도 업데이트를 거부하지 않는다
2. **탈중앙** — 마스터 노드 없이 모든 노드가 동등하다
3. **단일 관리 도메인** — 모든 노드를 신뢰할 수 있어 비잔틴 장애 허용이 불필요하고, 복잡성이 줄어든다

---

## 참고자료

- [Dynamo: Amazon's Highly Available Key-value Store (원문)](https://www.allthingsdistributed.com/files/amazon-dynamo-soho2007.pdf)
- [Dynamo 한글 번역본 (parksb)](https://parksb.github.io/papers-i-love/dynamo-amazons-highly-available-key-value-store.html)
- [Eventually Consistent - Werner Vogels](https://www.allthingsdistributed.com/2008/12/eventually_consistent.html) — Amazon CTO가 쓴 최종 일관성 해설
